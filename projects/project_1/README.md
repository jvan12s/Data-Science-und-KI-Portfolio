# ğŸ©º Herzstillstand-Vorhersage â€“ Abschlussbericht (Data Science Projekt)

## ğŸ“Œ Projektbeschreibung

In diesem Data-Science-Projekt wurde untersucht, ob es durch maschinelles Lernen mÃ¶glich ist, **HerzstillstÃ¤nde (Cardiac Arrest)** bei Patient:innen zuverlÃ¤ssig vorherzusagen.  
Die zugrunde liegenden medizinischen Daten enthalten verschiedene MessgrÃ¶ÃŸen und Merkmale. Die **Zielvariable** gibt an, ob ein Patient oder eine Patientin in der Zukunft von einem Herzstillstand betroffen sein wird (`1`) oder nicht (`0`).

### ğŸ¯ Zielsetzung

- Entwicklung und Vergleich zweier Klassifikationsmodelle.
- Analyse der **Praxistauglichkeit und Interpretierbarkeit** dieser Modelle in medizinischem Kontext.
- Formulierung einer Empfehlung fÃ¼r Mediziner:innen zur **anwendbaren RisikoeinschÃ¤tzung** basierend auf ML-Techniken.

---

## ğŸ§¾ Projektinhalt

### âœ… Datenaufbereitung

- **Reinigung der Daten**: Behandlung fehlender Werte, fehlerhafter EintrÃ¤ge und AusreiÃŸer.
- **Transformation**: Einheitliche Skalierung und Typisierung der Variablen.
- **Explorative Datenanalyse (EDA)**: Statistik, Histogramme, Korrelationen, Zielverteilung.

### ğŸ§  Feature Engineering

- Untersuchung von ZusammenhÃ¤ngen der Merkmale zur Zielvariable.
- Ausschluss unbrauchbarer und irrelevanter Variablen.
- Visualisierung der wichtigsten Korrelationen.

---

## ğŸ¤– Modellierung

Zwei verschiedene Klassifikationsalgorithmen wurden getestet und bewertet:

### 1. Logistische Regression

- **Beschreibung**: Einfache, erklÃ¤rbare Methode fÃ¼r binÃ¤re Klassifikation.
- **Vorteile**:
  - Gut interpretierbar (Merkmalsgewichtungen)
  - Transparente Entscheidungsregeln
- **Nachteile**:
  - Begrenzte ModellkomplexitÃ¤t
- **Erzielte Genauigkeit**: **ca. 80â€¯%**

### 2. Random Forest

- **Beschreibung**: Komplexes Ensemble-Modell (viele EntscheidungsbÃ¤ume).
- **Vorteile**:
  - Sehr hohe Genauigkeit
  - Robust gegenÃ¼ber AusreiÃŸern und Korrelationen
- **Nachteile**:
  - Kaum interpretierbar (â€Black Boxâ€œ)
- **Erzielte Genauigkeit**: **ca. 99â€¯%**

---

## ğŸ§ª Modellvergleich

| Modell               | PrÃ¤zision   | Interpretierbarkeit     | Empfehlung                                           |
|----------------------|-------------|--------------------------|------------------------------------------------------|
| Logistische Regression | ca. 80â€¯%  | Sehr gut                 | Ideal fÃ¼r medizinische Anwendungen mit Fokus auf Nachvollziehbarkeit |
| Random Forest          | ca. 99â€¯%  | Gering (â€Black Boxâ€œ)     | Maximale Erkennungsleistung bei reduzierter Transparenz |

ğŸ“ **Interpretation:**

- Die Logistische Regression erlaubt **direkte RÃ¼ckschlÃ¼sse auf Einflussfaktoren**.
- Der Random Forest erzielt extrem hohe Werte, eignet sich jedoch weniger fÃ¼r **erklÃ¤rbare medizinische Entscheidungen**.

---

## ğŸ§  Fazit & Empfehlung

FÃ¼r Anwendungen in der Medizin, wo **Transparenz, ErklÃ¤rbarkeit und VertrauenswÃ¼rdigkeit** entscheidend sind, **empfiehlt sich die Logistische Regression**.

Wenn jedoch die **hÃ¶chste Modellperformance** (Accuracy) im Vordergrund steht â€“ etwa bei datengetriebener Risikoanalyse â€“ kann der **Random Forest** ebenso sinnvoll sein.

---

## ğŸ”„ Weiterentwicklung

- Kombination beider Modelle: Logistische Regression zur BegrÃ¼ndung, Random Forest zur Validierung.
- Einsatz erklÃ¤rbarer KI-Methoden wie **SHAP** fÃ¼r Random Forest Interpretationen.
- Erweiterung des Datensatzes mit **LangzeitverlÃ¤ufen** oder **klinischen Zusatzdaten**.
