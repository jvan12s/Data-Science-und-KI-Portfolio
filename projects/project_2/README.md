# ğŸ“Š IMDb Sentiment Analysis â€“ Abschlussbericht

Dieses Projekt behandelt die **automatische Sentiment-Klassifikation von IMDb-Filmkritiken** (positiv oder negativ). Ziel war es, den Einsatz eines **einfachen neuronalen Netzes (Keras)** mit einem **klassischen Machine-Learning-Modell (logistische Regression mit scikit-learn)** zu vergleichen.

---

## ğŸ§  Zielsetzung

Ziel des Projekts war die Beantwortung der Frage:  
> **Wie stark unterscheiden sich ein einfaches neuronales Netz und ein klassisches ML-Modell bei der Textklassifikation anhand von IMDb-Kritiken?**

---

## ğŸ› ï¸ Verwendete Bibliotheken

- [`pandas`](https://pandas.pydata.org/) â€“ Datenverwaltung und -vorverarbeitung  
- [`scikit-learn`](https://scikit-learn.org/) â€“ Datenaufteilung, TF-IDF-Vektorisierung, Label-Encoding, logistisches Regressionsmodell  
- [`tensorflow` / `keras`](https://www.tensorflow.org/) â€“ Aufbau und Training des neuronalen Netzes  
- [`matplotlib`](https://matplotlib.org/) & [`seaborn`](https://seaborn.pydata.org/) â€“ Visualisierungen

---

## ğŸ§¹ Datenvorbereitung & Preprocessing

1. **Datenimport & Cleaning**:
   - Laden der IMDb-Daten
   - Entfernen unnÃ¶tiger Felder
2. **Label Encoding**:
   - Zielvariable â€Stimmungâ€œ (positiv = 1, negativ = 0)
3. **Text-Vektorisierung**:
   - Transformation des Textes in numerische Vektoren mit `TfidfVectorizer`
4. **Train-Test-Split**:
   - Aufteilung im VerhÃ¤ltnis 80/20 mit **stratifizierter Verteilung** zur Wahrung der Klassenbalance

---

## ğŸ§  Modellarchitektur & Training

### ğŸ”¹ Neuronales Netz (Keras)

- Architektur:  
  - `Dense(64, activation='relu')`  
  - `Dense(1, activation='sigmoid')`
- Optimizer: `Adam`  
- Loss: `BinaryCrossentropy`  
- Training: `5 Epochen`, standardmÃ¤ÃŸige Batch Size

### ğŸ”¸ Logistische Regression (scikit-learn)

- Klassisches ML-Modell ohne tieferes Hyperparameter-Tuning
- Nutzung des default `LogisticRegression()`-Objekts auf TF-IDF-Vektoren

---

## ğŸ“ˆ Evaluation & Ergebnisse

| Modell                  | Accuracy |
|-------------------------|----------|
| Neuronales Netz (Keras) | **0.8900** |
| Logistische Regression  | **0.8929** |

- Beide Modelle erreichen eine sehr gute Genauigkeit (~89â€¯%)
- Die **logistische Regression ist leicht besser**, obwohl das neuronale Netz grundsÃ¤tzlich flexibler ist

---

## ğŸ–¼ï¸ Visualisierung

- **Trainingsverlauf (Loss & Accuracy)** mit `matplotlib`
- **Vorhersageverteilung** mittels `seaborn` als Balkendiagramm
- Fokus auf **Accuracy** als Hauptmetrik

Beispielgrafiken:
- Trainingsverlauf als Liniengrafik
- Histogramm der Klassenvorhersagen

---

## ğŸ§¾ Fazit

- Klassische Modelle wie **logistische Regression** liefern bei der **Textklassifikation mit TF-IDF**-Vektoren oft **sehr starke Ergebnisse**.
- Tiefe neuronale Netze **sind nicht immer notwendig**, vor allem bei kleinen / mittleren Textdatenmengen.
- FÃ¼r viele Probleme im NLP (â€Natural Language Processingâ€œ) lohnt sich frÃ¼hzeitig ein **Modellvergleich verschiedener Klassen**.

---

## ğŸš€ Weiterentwicklung

- **Fortschrittlichere Architekturen** (z.â€¯B. LSTM, CNNs) ausprobieren
- **Pre-trained Embeddings** (z.â€¯B. Word2Vec, GloVe, BERT)
- **GrÃ¶ÃŸere DatensÃ¤tze** fÃ¼r das volle Potenzial neuronaler Modelle nutzen
- Einbindung von **Explainability Tools** (z.â€¯B. SHAP, LIME)

